{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 옵티마이저 비교\n",
    "옵티마이저 종류에는 RMSprop, Nadam , Adam, Adagrad가 있고 동일 조건 내에서 더 나은 옵티마이저를 찾는다.  \n",
    "조건 :  \n",
    "트레이닝-머니투데이190101200531 테스트-매일경제190101200531  \n",
    "주가 등락 기준의 상한 및 하한-0.0077이상 상승,-0.005이하에서 하락, 그 사이를 유지라고 가정  \n",
    "입력차원(사용 단어 수)-6000  \n",
    "에포크-고정60에 ModelcheckPoint로 the highest test_accuracy인 지점의 모델 사용  \n",
    "배치-전체 데이터 양의 1/5 ~1/6정도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용할 데이터의 형태\n",
    "data_type = '15'      # '1' : summarize X,개별 기사   '2' : summarize X,날짜별 기사\n",
    "                    # '3' : summarize O,개별 기사   '4' : summarize O,날짜별 기사\n",
    "normalized = 'done' # 'done' : 데이터 행별 normalize한 데이터     'not' : 데이터 행별 normalize 안한 데이터\n",
    "erased_word = ''    # 제거된 단어 형태\n",
    "num_word = '6000'   # 사용할 단어 수\n",
    "\n",
    "# 돌려볼 모델의 구조\n",
    "first_layer = 3000   # 모델의 첫 번째 레이어 수\n",
    "second_layer = 1000  # 모델의 두 번째 레이어 수\n",
    "ep = 60             # 모델의 에포크 수\n",
    "ba = 1024            # 모델의 배치 사이즈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생성된 training, test의 x,y값을 pickle의 형태로 저장\n",
    "import pickle\n",
    "import os\n",
    "path = os.getcwd()+'/pickles/'\n",
    "if erased_word != '':\n",
    "    erased_word = '_'+erased_word\n",
    "with open(path+data_type+'train_x_'+str(num_word)+'_'+normalized+erased_word+'.pickle', 'rb') as f:\n",
    "    train_x = pickle.load(f)\n",
    "with open(path+data_type+'train_y_'+str(num_word)+'_'+normalized+erased_word+'.pickle', 'rb') as f:\n",
    "    train_y = pickle.load(f)\n",
    "with open(path+data_type+'train2_x_'+str(num_word)+'_'+normalized+erased_word+'.pickle', 'rb') as f:\n",
    "    train2_x = pickle.load(f)\n",
    "with open(path+data_type+'train2_y_'+str(num_word)+'_'+normalized+erased_word+'.pickle', 'rb') as f:\n",
    "    train2_y = pickle.load(f)\n",
    "with open(path+data_type+'test_x_'+str(num_word)+'_'+normalized+erased_word+'.pickle', 'rb') as f:\n",
    "    test_x = pickle.load(f)\n",
    "with open(path+data_type+'test_y_'+str(num_word)+'_'+normalized+erased_word+'.pickle', 'rb') as f:\n",
    "    test_y = pickle.load(f)\n",
    "with open(path+data_type+'test2_x_'+str(num_word)+'_'+normalized+erased_word+'.pickle', 'rb') as f:\n",
    "    test2_x = pickle.load(f)\n",
    "with open(path+data_type+'test2_y_'+str(num_word)+'_'+normalized+erased_word+'.pickle', 'rb') as f:\n",
    "    test2_y = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy 사용하여 float로 바꾸어주는 과정\n",
    "import numpy as np\n",
    "x_train = np.asarray(train_x).astype('float32')\n",
    "y_train = np.asarray(train_y).astype('float32')\n",
    "x_test = np.asarray(test_x).astype('float32')\n",
    "y_test = np.asarray(test_y).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "5/5 [==============================] - ETA: 0s - loss: 1.0964 - categorical_accuracy: 0.3592INFO:tensorflow:Assets written to: test/assets\n",
      "5/5 [==============================] - 3s 594ms/step - loss: 1.0964 - categorical_accuracy: 0.3592 - val_loss: 1.0930 - val_categorical_accuracy: 0.3647\n",
      "Epoch 2/60\n",
      "5/5 [==============================] - ETA: 0s - loss: 1.0846 - categorical_accuracy: 0.3905INFO:tensorflow:Assets written to: test/assets\n",
      "5/5 [==============================] - 3s 564ms/step - loss: 1.0846 - categorical_accuracy: 0.3905 - val_loss: 1.0866 - val_categorical_accuracy: 0.4109\n",
      "Epoch 3/60\n",
      "5/5 [==============================] - 2s 408ms/step - loss: 1.0779 - categorical_accuracy: 0.4176 - val_loss: 1.0782 - val_categorical_accuracy: 0.3993\n",
      "Epoch 4/60\n",
      "5/5 [==============================] - 2s 410ms/step - loss: 1.0476 - categorical_accuracy: 0.4252 - val_loss: 1.1696 - val_categorical_accuracy: 0.3663\n",
      "Epoch 5/60\n",
      "5/5 [==============================] - 2s 455ms/step - loss: 1.0473 - categorical_accuracy: 0.4546 - val_loss: 1.0634 - val_categorical_accuracy: 0.4071\n",
      "Epoch 6/60\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.9855 - categorical_accuracy: 0.5042INFO:tensorflow:Assets written to: test/assets\n",
      "5/5 [==============================] - 3s 611ms/step - loss: 0.9855 - categorical_accuracy: 0.5042 - val_loss: 1.0367 - val_categorical_accuracy: 0.4672\n",
      "Epoch 7/60\n",
      "5/5 [==============================] - 2s 413ms/step - loss: 1.0256 - categorical_accuracy: 0.5159 - val_loss: 1.0348 - val_categorical_accuracy: 0.4616\n",
      "Epoch 8/60\n",
      "5/5 [==============================] - 2s 452ms/step - loss: 0.9046 - categorical_accuracy: 0.6106 - val_loss: 1.0508 - val_categorical_accuracy: 0.4430\n",
      "Epoch 9/60\n",
      "5/5 [==============================] - 2s 438ms/step - loss: 0.8943 - categorical_accuracy: 0.5865 - val_loss: 1.0925 - val_categorical_accuracy: 0.4474\n",
      "Epoch 10/60\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.8954 - categorical_accuracy: 0.5686INFO:tensorflow:Assets written to: test/assets\n",
      "5/5 [==============================] - 3s 608ms/step - loss: 0.8954 - categorical_accuracy: 0.5686 - val_loss: 1.0326 - val_categorical_accuracy: 0.4795\n",
      "Epoch 11/60\n",
      "5/5 [==============================] - 2s 419ms/step - loss: 0.8930 - categorical_accuracy: 0.5981 - val_loss: 1.0518 - val_categorical_accuracy: 0.4741\n",
      "Epoch 12/60\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.7866 - categorical_accuracy: 0.6611INFO:tensorflow:Assets written to: test/assets\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.7866 - categorical_accuracy: 0.6611 - val_loss: 1.0487 - val_categorical_accuracy: 0.4842\n",
      "Epoch 13/60\n",
      "5/5 [==============================] - 2s 479ms/step - loss: 0.7694 - categorical_accuracy: 0.6546 - val_loss: 1.1617 - val_categorical_accuracy: 0.4140\n",
      "Epoch 14/60\n",
      "5/5 [==============================] - 2s 464ms/step - loss: 0.7507 - categorical_accuracy: 0.6919 - val_loss: 1.1023 - val_categorical_accuracy: 0.4708\n",
      "Epoch 15/60\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.8380 - categorical_accuracy: 0.6197INFO:tensorflow:Assets written to: test/assets\n",
      "5/5 [==============================] - 3s 649ms/step - loss: 0.8380 - categorical_accuracy: 0.6197 - val_loss: 1.0554 - val_categorical_accuracy: 0.4903\n",
      "Epoch 16/60\n",
      "5/5 [==============================] - 2s 429ms/step - loss: 0.6745 - categorical_accuracy: 0.7259 - val_loss: 1.0490 - val_categorical_accuracy: 0.4710\n",
      "Epoch 17/60\n",
      "5/5 [==============================] - 2s 443ms/step - loss: 0.7138 - categorical_accuracy: 0.6781 - val_loss: 1.0979 - val_categorical_accuracy: 0.4818\n",
      "Epoch 18/60\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.6559 - categorical_accuracy: 0.7297INFO:tensorflow:Assets written to: test/assets\n",
      "5/5 [==============================] - 3s 638ms/step - loss: 0.6559 - categorical_accuracy: 0.7297 - val_loss: 1.0595 - val_categorical_accuracy: 0.4967\n",
      "Epoch 19/60\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.6309 - categorical_accuracy: 0.7375INFO:tensorflow:Assets written to: test/assets\n",
      "5/5 [==============================] - 3s 610ms/step - loss: 0.6309 - categorical_accuracy: 0.7375 - val_loss: 1.0689 - val_categorical_accuracy: 0.5024\n",
      "Epoch 20/60\n",
      "5/5 [==============================] - 2s 435ms/step - loss: 0.6275 - categorical_accuracy: 0.7364 - val_loss: 1.1599 - val_categorical_accuracy: 0.4675\n",
      "Epoch 21/60\n",
      "5/5 [==============================] - 2s 449ms/step - loss: 0.5828 - categorical_accuracy: 0.7542 - val_loss: 1.1754 - val_categorical_accuracy: 0.4430\n",
      "Epoch 22/60\n",
      "5/5 [==============================] - 2s 449ms/step - loss: 0.5412 - categorical_accuracy: 0.7828 - val_loss: 1.2263 - val_categorical_accuracy: 0.4863\n",
      "Epoch 23/60\n",
      "5/5 [==============================] - 2s 444ms/step - loss: 0.6007 - categorical_accuracy: 0.7321 - val_loss: 1.0849 - val_categorical_accuracy: 0.4875\n",
      "Epoch 24/60\n",
      "5/5 [==============================] - 2s 443ms/step - loss: 0.4507 - categorical_accuracy: 0.8463 - val_loss: 1.4957 - val_categorical_accuracy: 0.4564\n",
      "Epoch 25/60\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.6122 - categorical_accuracy: 0.7261INFO:tensorflow:Assets written to: test/assets\n",
      "5/5 [==============================] - 3s 620ms/step - loss: 0.6122 - categorical_accuracy: 0.7261 - val_loss: 1.1772 - val_categorical_accuracy: 0.5054\n",
      "Epoch 26/60\n",
      "5/5 [==============================] - 2s 430ms/step - loss: 0.4347 - categorical_accuracy: 0.8369 - val_loss: 1.3653 - val_categorical_accuracy: 0.4804\n",
      "Epoch 27/60\n",
      "5/5 [==============================] - 2s 461ms/step - loss: 0.5078 - categorical_accuracy: 0.7842 - val_loss: 1.3392 - val_categorical_accuracy: 0.4397\n",
      "Epoch 28/60\n",
      "5/5 [==============================] - 2s 461ms/step - loss: 0.4487 - categorical_accuracy: 0.8255 - val_loss: 1.2964 - val_categorical_accuracy: 0.4983\n",
      "Epoch 29/60\n",
      "5/5 [==============================] - 2s 450ms/step - loss: 0.4414 - categorical_accuracy: 0.8119 - val_loss: 1.3489 - val_categorical_accuracy: 0.4917\n",
      "Epoch 30/60\n",
      "5/5 [==============================] - 2s 447ms/step - loss: 0.4587 - categorical_accuracy: 0.8090 - val_loss: 1.2838 - val_categorical_accuracy: 0.4750\n",
      "Epoch 31/60\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.3344 - categorical_accuracy: 0.8838INFO:tensorflow:Assets written to: test/assets\n",
      "5/5 [==============================] - 3s 637ms/step - loss: 0.3344 - categorical_accuracy: 0.8838 - val_loss: 1.2570 - val_categorical_accuracy: 0.5118\n",
      "Epoch 32/60\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.4520 - categorical_accuracy: 0.8059INFO:tensorflow:Assets written to: test/assets\n",
      "5/5 [==============================] - 3s 614ms/step - loss: 0.4520 - categorical_accuracy: 0.8059 - val_loss: 1.2136 - val_categorical_accuracy: 0.5257\n",
      "Epoch 33/60\n",
      "5/5 [==============================] - 2s 434ms/step - loss: 0.2369 - categorical_accuracy: 0.9390 - val_loss: 1.6504 - val_categorical_accuracy: 0.4326\n",
      "Epoch 34/60\n",
      "5/5 [==============================] - 2s 463ms/step - loss: 0.5470 - categorical_accuracy: 0.8083 - val_loss: 1.2607 - val_categorical_accuracy: 0.5255\n",
      "Epoch 35/60\n",
      "5/5 [==============================] - 2s 447ms/step - loss: 0.4003 - categorical_accuracy: 0.8382 - val_loss: 1.1566 - val_categorical_accuracy: 0.5172\n",
      "Epoch 36/60\n",
      "5/5 [==============================] - 2s 449ms/step - loss: 0.2249 - categorical_accuracy: 0.9502 - val_loss: 1.5475 - val_categorical_accuracy: 0.5101\n",
      "Epoch 37/60\n",
      "5/5 [==============================] - 2s 451ms/step - loss: 0.4056 - categorical_accuracy: 0.8275 - val_loss: 1.2509 - val_categorical_accuracy: 0.5059\n",
      "Epoch 38/60\n",
      "5/5 [==============================] - 2s 457ms/step - loss: 0.2315 - categorical_accuracy: 0.9294 - val_loss: 1.4362 - val_categorical_accuracy: 0.4929\n",
      "Epoch 39/60\n",
      "5/5 [==============================] - 2s 450ms/step - loss: 0.2841 - categorical_accuracy: 0.8867 - val_loss: 1.3421 - val_categorical_accuracy: 0.5226\n",
      "Epoch 40/60\n",
      "5/5 [==============================] - 2s 448ms/step - loss: 0.2812 - categorical_accuracy: 0.8950 - val_loss: 1.7347 - val_categorical_accuracy: 0.4901\n",
      "Epoch 41/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 450ms/step - loss: 0.2323 - categorical_accuracy: 0.9261 - val_loss: 1.4425 - val_categorical_accuracy: 0.5250\n",
      "Epoch 42/60\n",
      "5/5 [==============================] - 2s 451ms/step - loss: 0.3486 - categorical_accuracy: 0.8584 - val_loss: 1.2593 - val_categorical_accuracy: 0.4953\n",
      "Epoch 43/60\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.2001 - categorical_accuracy: 0.9471INFO:tensorflow:Assets written to: test/assets\n",
      "5/5 [==============================] - 3s 625ms/step - loss: 0.2001 - categorical_accuracy: 0.9471 - val_loss: 1.4091 - val_categorical_accuracy: 0.5278\n",
      "Epoch 44/60\n",
      "5/5 [==============================] - 2s 426ms/step - loss: 0.1260 - categorical_accuracy: 0.9687 - val_loss: 1.5138 - val_categorical_accuracy: 0.5151\n",
      "Epoch 45/60\n",
      "5/5 [==============================] - 2s 450ms/step - loss: 0.2855 - categorical_accuracy: 0.8838 - val_loss: 2.0044 - val_categorical_accuracy: 0.4811\n",
      "Epoch 46/60\n",
      "5/5 [==============================] - 2s 447ms/step - loss: 0.2278 - categorical_accuracy: 0.9276 - val_loss: 1.5512 - val_categorical_accuracy: 0.5189\n",
      "Epoch 47/60\n",
      "5/5 [==============================] - 2s 444ms/step - loss: 0.1568 - categorical_accuracy: 0.9524 - val_loss: 1.6947 - val_categorical_accuracy: 0.4729\n",
      "Epoch 48/60\n",
      "5/5 [==============================] - 2s 443ms/step - loss: 0.2324 - categorical_accuracy: 0.9093 - val_loss: 1.5656 - val_categorical_accuracy: 0.5259\n",
      "Epoch 49/60\n",
      "5/5 [==============================] - 2s 441ms/step - loss: 0.0836 - categorical_accuracy: 0.9832 - val_loss: 1.5886 - val_categorical_accuracy: 0.5276\n",
      "Epoch 50/60\n",
      "5/5 [==============================] - 2s 446ms/step - loss: 0.1808 - categorical_accuracy: 0.9321 - val_loss: 3.0358 - val_categorical_accuracy: 0.4727\n",
      "Epoch 51/60\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.4685 - categorical_accuracy: 0.8566INFO:tensorflow:Assets written to: test/assets\n",
      "5/5 [==============================] - 3s 621ms/step - loss: 0.4685 - categorical_accuracy: 0.8566 - val_loss: 1.4309 - val_categorical_accuracy: 0.5351\n",
      "Epoch 52/60\n",
      "5/5 [==============================] - 2s 431ms/step - loss: 0.0774 - categorical_accuracy: 0.9868 - val_loss: 1.6137 - val_categorical_accuracy: 0.5344\n",
      "Epoch 53/60\n",
      "5/5 [==============================] - 2s 445ms/step - loss: 0.0655 - categorical_accuracy: 0.9855 - val_loss: 1.6757 - val_categorical_accuracy: 0.5309\n",
      "Epoch 54/60\n",
      "5/5 [==============================] - 2s 442ms/step - loss: 0.0891 - categorical_accuracy: 0.9754 - val_loss: 2.6748 - val_categorical_accuracy: 0.4613\n",
      "Epoch 55/60\n",
      "5/5 [==============================] - 2s 442ms/step - loss: 0.4977 - categorical_accuracy: 0.8215 - val_loss: 1.4258 - val_categorical_accuracy: 0.5349\n",
      "Epoch 56/60\n",
      "5/5 [==============================] - 2s 454ms/step - loss: 0.0687 - categorical_accuracy: 0.9902 - val_loss: 1.6348 - val_categorical_accuracy: 0.5337\n",
      "Epoch 57/60\n",
      "5/5 [==============================] - 2s 451ms/step - loss: 0.0515 - categorical_accuracy: 0.9893 - val_loss: 1.8171 - val_categorical_accuracy: 0.5302\n",
      "Epoch 58/60\n",
      "5/5 [==============================] - 2s 445ms/step - loss: 0.0484 - categorical_accuracy: 0.9877 - val_loss: 1.8504 - val_categorical_accuracy: 0.5295\n",
      "Epoch 59/60\n",
      "5/5 [==============================] - 2s 452ms/step - loss: 0.0590 - categorical_accuracy: 0.9826 - val_loss: 2.9129 - val_categorical_accuracy: 0.4816\n",
      "Epoch 60/60\n",
      "5/5 [==============================] - 2s 440ms/step - loss: 1.0069 - categorical_accuracy: 0.6595 - val_loss: 1.4674 - val_categorical_accuracy: 0.5297\n"
     ]
    }
   ],
   "source": [
    "# DNN 학습 모델\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "callbacks = [ModelCheckpoint(filepath='test',monitor='val_categorical_accuracy',save_best_only=True)]\n",
    "model = models.Sequential()\n",
    "n =len(x_train[0])\n",
    "model.add(layers.Dense(first_layer,activation='relu'))#실제 쓸 단어갯수\n",
    "\n",
    "model.add(layers.Dense(second_layer,activation='relu'))\n",
    "\n",
    "model.add(layers.Dense(3,activation='softmax'))\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001),loss = losses.categorical_crossentropy,metrics=[metrics.categorical_accuracy])\n",
    "\n",
    "hist = model.fit(x_train,y_train,epochs=ep,validation_data=(x_test,y_test),callbacks=callbacks,batch_size=ba)\n",
    "#hist = model.fit(x_train,y_train,epochs=ep,validation_data=(x_test,y_test),batch_size=ba)\n",
    "\n",
    "# 모델의 예측값을 튜플로 반환하는 함수\n",
    "def predict(x):\n",
    "    data = np.expand_dims(np.asarray(x).astype('float32'),axis=0)\n",
    "    result = model.predict(data)\n",
    "    return tuple(result[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_best = models.load_model('test')\n",
    "\n",
    "def b_predict(x):\n",
    "    data = np.expand_dims(np.asarray(x).astype('float32'),axis=0)\n",
    "    result = model_best.predict(data)\n",
    "    return tuple(result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 날짜의 예측값들을 합치기 위한 튜플의 합 함수\n",
    "\n",
    "def sum_tuple(a,b):\n",
    "    return (a[0]+b[0],a[1]+b[1],a[2]+b[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 타입 : 15\n",
      "단어 갯수 : 6000\n",
      "행당 노말라이즈 : done\n",
      "모델 레이어 및 노드 수 :  첫 번째 레이어 - relu, 3000 , 두 번째 레이어 - relu, 1000\n",
      "epochs :  60 , batch_size :  1024\n",
      "test 데이터 정확도 :  0.6829971181556196\n"
     ]
    }
   ],
   "source": [
    "# Test set에 대한 예측 및 예측 정확도의 계산\n",
    "#money190101을 트레이닝으로 삼은 모델로 final_maekyung190101예측결과) 0.0077 -0.005\n",
    "#optimizer: Adam\n",
    "import re\n",
    "print('데이터 타입 : '+data_type)\n",
    "print('단어 갯수 : '+num_word)\n",
    "print('행당 노말라이즈 : '+ normalized)\n",
    "print('모델 레이어 및 노드 수 : ','첫 번째 레이어 - relu,',first_layer,', 두 번째 레이어 - relu,',second_layer)\n",
    "print('epochs : ',ep,', batch_size : ', ba)\n",
    "\n",
    "count = 0\n",
    "sum_dic = {}\n",
    "for data in test2_x:\n",
    "    result = b_predict(data[0])\n",
    "    if data[1] in sum_dic:\n",
    "        sum_dic[data[1]] = sum_tuple(sum_dic[data[1]],result)\n",
    "    else:\n",
    "        sum_dic[data[1]] = result\n",
    "    \n",
    "for date in sum_dic:\n",
    "    real = test2_y[date]\n",
    "    value = sum_dic[date].index(max(sum_dic[date]))\n",
    "    value -= 1\n",
    "    if real == value:\n",
    "        count = count + 1\n",
    "test_score = count / len(sum_dic)\n",
    "\n",
    "\n",
    "#print('train 데이터 정확도 : ', train_score)\n",
    "print('test 데이터 정확도 : ', test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 타입 : 15\n",
      "단어 갯수 : 6000\n",
      "행당 노말라이즈 : done\n",
      "모델 레이어 및 노드 수 :  첫 번째 레이어 - relu, 3000 , 두 번째 레이어 - relu, 1000\n",
      "epochs :  60 , batch_size :  1024\n",
      "test 데이터 정확도 :  0.7435158501440923\n"
     ]
    }
   ],
   "source": [
    "# Test set에 대한 예측 및 예측 정확도의 계산\n",
    "#money190101을 트레이닝으로 삼은 모델로 final_maekyung190101예측결과) 0.0077 -0.005\n",
    "#optimizer: Nadam\n",
    "import re\n",
    "print('데이터 타입 : '+data_type)\n",
    "print('단어 갯수 : '+num_word)\n",
    "print('행당 노말라이즈 : '+ normalized)\n",
    "print('모델 레이어 및 노드 수 : ','첫 번째 레이어 - relu,',first_layer,', 두 번째 레이어 - relu,',second_layer)\n",
    "print('epochs : ',ep,', batch_size : ', ba)\n",
    "\n",
    "count = 0\n",
    "sum_dic = {}\n",
    "for data in test2_x:\n",
    "    result = b_predict(data[0])\n",
    "    if data[1] in sum_dic:\n",
    "        sum_dic[data[1]] = sum_tuple(sum_dic[data[1]],result)\n",
    "    else:\n",
    "        sum_dic[data[1]] = result\n",
    "    \n",
    "for date in sum_dic:\n",
    "    real = test2_y[date]\n",
    "    value = sum_dic[date].index(max(sum_dic[date]))\n",
    "    value -= 1\n",
    "    if real == value:\n",
    "        count = count + 1\n",
    "test_score = count / len(sum_dic)\n",
    "\n",
    "\n",
    "#print('train 데이터 정확도 : ', train_score)\n",
    "print('test 데이터 정확도 : ', test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 타입 : 15\n",
      "단어 갯수 : 6000\n",
      "행당 노말라이즈 : done\n",
      "모델 레이어 및 노드 수 :  첫 번째 레이어 - relu, 3000 , 두 번째 레이어 - relu, 1000\n",
      "epochs :  60 , batch_size :  1024\n",
      "test 데이터 정확도 :  0.3400576368876081\n"
     ]
    }
   ],
   "source": [
    "# Test set에 대한 예측 및 예측 정확도의 계산\n",
    "#money190101을 트레이닝으로 삼은 모델로 final_maekyung190101예측결과) 0.0077 -0.005\n",
    "#optimizer: adagrad\n",
    "import re\n",
    "print('데이터 타입 : '+data_type)\n",
    "print('단어 갯수 : '+num_word)\n",
    "print('행당 노말라이즈 : '+ normalized)\n",
    "print('모델 레이어 및 노드 수 : ','첫 번째 레이어 - relu,',first_layer,', 두 번째 레이어 - relu,',second_layer)\n",
    "print('epochs : ',ep,', batch_size : ', ba)\n",
    "\n",
    "count = 0\n",
    "sum_dic = {}\n",
    "for data in test2_x:\n",
    "    result = b_predict(data[0])\n",
    "    if data[1] in sum_dic:\n",
    "        sum_dic[data[1]] = sum_tuple(sum_dic[data[1]],result)\n",
    "    else:\n",
    "        sum_dic[data[1]] = result\n",
    "    \n",
    "for date in sum_dic:\n",
    "    real = test2_y[date]\n",
    "    value = sum_dic[date].index(max(sum_dic[date]))\n",
    "    value -= 1\n",
    "    if real == value:\n",
    "        count = count + 1\n",
    "test_score = count / len(sum_dic)\n",
    "\n",
    "\n",
    "#print('train 데이터 정확도 : ', train_score)\n",
    "print('test 데이터 정확도 : ', test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 타입 : 15\n",
      "단어 갯수 : 6000\n",
      "행당 노말라이즈 : done\n",
      "모델 레이어 및 노드 수 :  첫 번째 레이어 - relu, 3000 , 두 번째 레이어 - relu, 1000\n",
      "epochs :  60 , batch_size :  1024\n",
      "test 데이터 정확도 :  0.7838616714697406\n"
     ]
    }
   ],
   "source": [
    "# Test set에 대한 예측 및 예측 정확도의 계산\n",
    "#money190101을 트레이닝으로 삼은 모델로 final_maekyung190101예측결과) 0.0077 -0.005\n",
    "#optimizer :RMSprop\n",
    "import re\n",
    "print('데이터 타입 : '+data_type)\n",
    "print('단어 갯수 : '+num_word)\n",
    "print('행당 노말라이즈 : '+ normalized)\n",
    "print('모델 레이어 및 노드 수 : ','첫 번째 레이어 - relu,',first_layer,', 두 번째 레이어 - relu,',second_layer)\n",
    "print('epochs : ',ep,', batch_size : ', ba)\n",
    "\n",
    "count = 0\n",
    "sum_dic = {}\n",
    "for data in test2_x:\n",
    "    result = b_predict(data[0])\n",
    "    if data[1] in sum_dic:\n",
    "        sum_dic[data[1]] = sum_tuple(sum_dic[data[1]],result)\n",
    "    else:\n",
    "        sum_dic[data[1]] = result\n",
    "    \n",
    "for date in sum_dic:\n",
    "    real = test2_y[date]\n",
    "    value = sum_dic[date].index(max(sum_dic[date]))\n",
    "    value -= 1\n",
    "    if real == value:\n",
    "        count = count + 1\n",
    "test_score = count / len(sum_dic)\n",
    "\n",
    "\n",
    "#print('train 데이터 정확도 : ', train_score)\n",
    "print('test 데이터 정확도 : ', test_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
